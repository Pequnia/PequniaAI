{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# PequniaAI: Personalized AI Agent Training\n",
    "In this notebook, we will train personalized AI agents based on their behavior and specific traits. Each agent is described by attributes like age, gender, behavior, and unique traits. We'll process the data, train a neural network model, and evaluate the agents' responses to different input prompts.\n"
   ],
   "id": "2503b7048f68b6c3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n"
   ],
   "id": "1111171c3932a185"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "data = pd.read_csv(\"data.csv\")\n",
    "\n",
    "data.head()\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def preprocess_data(df):\n",
    "    tokens = tokenizer(df['Specific Traits'].tolist(), padding=True, truncation=True, return_tensors=\"pt\", max_length=50)\n",
    "    return tokens\n",
    "\n",
    "tokens = preprocess_data(data)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "data['Behavior_Label'] = label_encoder.fit_transform(data['Behavior'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(tokens['input_ids'], data['Behavior_Label'], test_size=0.2, random_state=42)\n"
   ],
   "id": "959a249a3de837e2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define the neural network model using an LSTM for sequential text processing\n",
    "class TraitPredictionNN(nn.Module):\n",
    "    def __init__(self, hidden_size=128):\n",
    "        super(TraitPredictionNN, self).__init__()\n",
    "\n",
    "        # Embedding layer and LSTM layer\n",
    "        self.embedding = nn.Embedding(30522, hidden_size)  # BERT vocab size\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, hidden_size)\n",
    "        self.output_layer = nn.Linear(hidden_size, 3)  # 3 possible behavior classes (friendly, professional, humorous)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through the layers\n",
    "        x = self.embedding(x)\n",
    "        x, (hn, cn) = self.lstm(x)\n",
    "        x = self.fc(x[:, -1, :])  # Take the last LSTM output\n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = TraitPredictionNN()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ],
   "id": "332e166e7ef4add9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Train the model on the data\n",
    "def train_model(model, X_train, y_train, epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        output = model(X_train)\n",
    "\n",
    "        # Calculate loss\n",
    "        loss = criterion(output, y_train)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Convert X_train and y_train to tensors\n",
    "X_train_tensor = torch.tensor(X_train.tolist(), dtype=torch.long)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, X_train_tensor, y_train_tensor, epochs=5)\n"
   ],
   "id": "b3daf3013896336"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Function to evaluate the model's accuracy on the test set\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    model.eval()\n",
    "\n",
    "    # Convert X_test and y_test to tensors\n",
    "    X_test_tensor = torch.tensor(X_test.tolist(), dtype=torch.long)\n",
    "    y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(X_test_tensor)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        accuracy = (predicted == y_test_tensor).float().mean()\n",
    "\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate_model(model, X_test, y_test)\n"
   ],
   "id": "7a8b23c3e86ce35"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Function to predict the behavior of a new input\n",
    "def predict_behavior(model, input_text):\n",
    "    model.eval()\n",
    "\n",
    "    # Tokenize the input text\n",
    "    input_tokens = tokenizer(input_text, padding=True, truncation=True, return_tensors=\"pt\", max_length=50)\n",
    "\n",
    "    # Get the prediction from the model\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tokens['input_ids'])\n",
    "        _, predicted = torch.max(output, 1)\n",
    "\n",
    "    # Decode the predicted label to its corresponding behavior\n",
    "    predicted_behavior = label_encoder.inverse_transform(predicted.numpy())\n",
    "    return predicted_behavior[0]\n",
    "\n",
    "# Example prediction\n",
    "test_input = \"I like to tell jokes and make people laugh, but I always maintain professionalism.\"\n",
    "predicted_behavior = predict_behavior(model, test_input)\n",
    "print(f\"Predicted Behavior: {predicted_behavior}\")\n"
   ],
   "id": "b66dd369fe420454"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Save the trained model to a file for future use\n",
    "torch.save(model.state_dict(), \"pequniaAI_model.pth\")\n"
   ],
   "id": "2526cc5847d41869"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Load the trained model from the saved file\n",
    "model.load_state_dict(torch.load(\"pequniaAI_model.pth\"))\n",
    "\n",
    "# Example prediction using the loaded model\n",
    "test_input = \"I prefer concise and formal communication, focusing on technical topics.\"\n",
    "predicted_behavior = predict_behavior(model, test_input)\n",
    "print(f\"Predicted Behavior: {predicted_behavior}\")\n"
   ],
   "id": "687677f5856b0084"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
